---
title: "Orderly Tutorial"
author: "MRC Centre for Global Infectious Disease Analysis"
format:
  revealjs:
    preview-links: auto
execute:
  echo: true
  error: true
  message: true
  output: true
  warning: true
project:
  execute-dir: workdir
---

```{r}
#| include: false
#| cache: false
source("support.R")
unlink("workdir/part1", recursive = TRUE)
unlink("workdir/part2", recursive = TRUE)
unlink("workdir/part3", recursive = TRUE)
```

# What is orderly?

::: {.incremental}
- A reproducible reporting framework
- A way of keeping track of versions of data
- A way of collaborating with other people
- A way of thinking about analysis
:::

## Original aims:

> “With orderly we have two main hopes:
>
> - analysts can write code that will straightforwardly run on someone else’s machine (or a remote machine)
> - when an analysis that is run several times starts behaving differently it will be easy to see when the outputs started changing, and what inputs started changing at the same time”

(~ 2018)

::: {.notes}
orderly requires a few conventions around organisation of a project, and after that tries to keep out of your way. However, these requirements are designed to make collaborative development with git easier by minimising conflicts and making backup easier by using an append-only storage system.
:::

## But what is it? {.smaller}

* A [package](https://mrc-ide.github.io/orderly2) designed to make analysis more reproducible
* A way of structuring your analysis so to make it easy to understand, run and reuse
* A set of tools that make it easy to:
  - track all **inputs** into an analysis (packages, code, and data resources)
  - store multiple **versions** of an analysis where it is repeated
  - track **outputs** of an analysis
  - create analyses that **depend** on the outputs of previous analyses

## Who uses it?

- Developed since May 2017 for the [Vaccine Impact Modelling Consortium](https://www.vaccineimpact.org/)
- Used in the 2018-2020 DRC Ebola responses
- Used in the COVID-19 response, especially within the "real time modelling" group
- Used within research groups (HIV, Malaria, possibly others?)

## Historical notes {.smaller}

* [`orderly`](https://vimc.github.io/orderly) (version 1)
  - Created for [Vaccine Impact Modelling Consortium](https://www.vaccineimpact.org/) and strongly focussed on **reproducible research**
  - Used [YAML](https://en.wikipedia.org/wiki/YAML) everywhere
  - Supported simple ways of working for a small centralised team
* [`orderly2`](https://mrc-ide.github.io/orderly2) (soon to be `orderly` 2.0.0)
  - A complete rewrite taking the best ideas from version 1 and dropping many less useful bits
  - Easier to program against
  - No more YAML
  - Focusses on **distributed collaborative analysis**
  - Also available as a [python package](https://pypi.org/project/pyorderly/)!

# Part 1: Getting started {background="#43464B"}

## Install `orderly2`

From the mrc-ide [r-universe](https://mrc-ide.r-universe.dev) (recommended)

```r
install.packages(
  "orderly2",
  repos = c("https://mrc-ide.r-universe.dev",
            "https://cloud.r-project.org"))
```

From GitHub using `remotes`:

```r
remotes::install_github("mrc-ide/orderly2")
```

From PyPi (for Python)

```r
pip install pyorderly
```

## My first orderly report / task

. . .

There is a discussion to have here about naming.  We might have this in a break...

## The setup

First, load the package and create a new empty orderly root.

```{r}
library(orderly2)
orderly_init("workdir/part1")
```

(for the rest of this section, we have `setwd()` into this directory; you should create an RStudio "Project" here.)

```{r}
#| include: false
Sys.setenv(ORDERLY_ROOT = "workdir/part1")
```

. . .

## What's in the box?

```{r}
fs::dir_tree("workdir/part1")
```

. . .

Really:


```{r}
fs::dir_tree("workdir/part1", all = TRUE)
```

But leave everything in `.outpack/` alone, just like `.git/`

## Create an empty report

```{r}
orderly_new("example")
```

. . .

Our contents now:

```{r}
fs::dir_tree("workdir/part1")
```

The name `example.R` is important; this always has the form `src/<name>/name.R`

## Hello orderly world

```{r}
#| include: false
fs::file_copy("inputs/part1/hello.R",
              "workdir/part1/src/example/example.R",
overwrite = TRUE)
```

We have edited `src/example/example.R` to contain:

```{r}
#| echo: false
#| results: asis
r_output(readLines("workdir/part1/src/example/example.R"))
```

Now we run

```{r}
id <- orderly_run("example")
```

## Files created {.smaller}

```{r}
fs::dir_tree("workdir/part1")
```

* Directory named after the id (in `archive/example`)
* We have copied `example.R` into the directory
* Output sits next to inputs
* Metadata is stored in a hidden location

Contents of `hello.csv`:

```{r}
read.csv(file.path("workdir/part1/archive/example", id, "hello.csv"))
```

## Every packet has a unique id {.smaller}

```{r}
id
```

and a bunch of metadata:

```{r}
orderly_metadata(id)
```

## What is a hash?

A one-way transformation from data to a fairly short string

```{r}
orderly_hash_data("hello", "sha256")
```

. . .

Very small changes to the string give large changes to the hash

```{r}
orderly_hash_data("hel1o", "sha256")
```

. . .

This means we can compare hashes and be confident we are looking at the same file (`git` does a lot of this)

## Run it again, Sam {.smaller}

```{r}
orderly_run("example")
```

* We have a new id with the new copy

## A copy saved every time we run  {.smaller}

Stop naming files `data_final-rgf (2).csv`, please

```{r}
fs::dir_tree("workdir/part1")
```

## A high-level overview of of packets:

```{r}
orderly_metadata_extract()
```

(more on this later).

# Part 2: orderly code {background="#43464B"}

## What can I do?

* orderly code is any code you can use from R
* Use (almost) any package, any sort of file

But...

* The directory above your file **does not exist**
* Don't use absolute paths or `../` path fragments
* You can add metadata to help future you/others

## A clean beginning

```{r}
orderly_init("workdir/part2")
```

```{r}
#| include: false
Sys.setenv(ORDERLY_ROOT = "workdir/part2")
```

Suppose we're working on a data analysis pipeline, starting with "incoming data":

```{r}
orderly_new("incoming")
```

Our setup:

```{r}
fs::dir_tree("workdir/part2")
```

## Incoming data {.smaller}

```{r}
#| include: false
fs::file_copy("inputs/part2/data.xlsx", "workdir/part2/src/incoming")
fs::file_copy("inputs/part2/incoming-1.R",
              "workdir/part2/src/incoming/incoming.R", overwrite = TRUE)
```

I've copied some data in as `data.xlsx` into `src/incoming`.

```{r}
fs::dir_tree("workdir/part2")
```

* Modify `incoming.R` to tidy that up for consumption using your favourite packages.
* Set your working directory to `src/incoming` and just edit things as usual
* Which sheet contains the data?
* Where is the data in that sheet?
* Do you like those column names?
* How about that date format?

## Incoming data, cleaned

My attempt at cleaning:

```{r}
#| echo: false
#| results: asis
r_output(readLines("workdir/part2/src/incoming/incoming.R"))
```

* Read in the data
* Clean up the names (could have used `janitor`)
* Convert date format
* Write as `csv`

## Incoming data, running things {.smaller}

```{r}
id <- orderly_run("incoming")
```

Our generated metadata:

```{r}
orderly_metadata(id)
```

## "Resources"

* Any file that is an **input**
* For example:
  - Scripts that you `source()`
  - R Markdown files for `knitr` or `rmarkdown`
  - Data files (`.csv`, `.xlsx`, etc)
  - Plain text files (`README.md`, licence info, etc)
* Here, `data.xlsx` is an input

## Telling orderly about resources {.smaller}

```{r}
#| include: false
fs::file_copy("inputs/part2/incoming-2.R",
              "workdir/part2/src/incoming/incoming.R", overwrite = TRUE)
```
```{r}
#| echo: false
#| results: asis
r_output(readLines("workdir/part2/src/incoming/incoming.R"))
```

. . .

* Tells orderly `data.xlsx` is a **resource**
* Fail early if resource not found
* Error if resource is modified
* Extra metadata, advertising what files **were used**

. . .

```{r}
id <- orderly_run("incoming")
orderly_metadata(id)$custom$orderly$role
```

## "Artefacts"

* Any file that is an **output**
* For example:
  - Datasets you generate
  - html or pdf output from `knitr` or `rmarkdown`
  - Plain text files
  - Inputs themselves, sometimes
* Here, `data.csv` is an artefact

## Telling orderly about artefacts {.smaller}

```{r}
#| include: false
fs::file_copy("inputs/part2/incoming-3.R",
              "workdir/part2/src/incoming/incoming.R", overwrite = TRUE)
```
```{r}
#| echo: false
#| results: asis
r_output(readLines("workdir/part2/src/incoming/incoming.R"))
```

. . .

* Tells orderly `csv.xlsx` is an **artefact**
* Fail if artefact not produced
* Extra metadata, advertising what files **were produced**

. . .

```{r}
id <- orderly_run("incoming")
orderly_metadata(id)$custom$orderly$artefacts
```

## More metadata {.smaller}

```{r}
#| include: false
fs::file_copy("inputs/part2/incoming-4.R",
              "workdir/part2/src/incoming/incoming.R", overwrite = TRUE)
```
```{r}
#| echo: false
#| results: asis
r_output(readLines("workdir/part2/src/incoming/incoming.R"))
```

Running this:

```{r}
id <- orderly_run("incoming", echo = FALSE)
orderly_metadata(id)$custom$orderly$description
```

## Dependencies

* This is really the point of orderly
* You can pull in any file from any previously run packet
* You can use queries to select packets to depend on

**Our aim**: We want to use `data.csv` in some analysis

```{r}
orderly_new("analysis")
```

## Setting up a dependency

```{r}
#| include: false
fs::file_copy("inputs/part2/analysis.R",
              "workdir/part2/src/analysis/analysis.R", overwrite = TRUE)
```
```{r}
#| echo: false
#| results: asis
r_output(readLines("workdir/part2/src/analysis/analysis.R"))
```

This is the only file within our analysis directory:

```{r}
fs::dir_tree("workdir/part2/src/analysis")
```

## Running the report {.smaller}

```{r}
id <- orderly_run("analysis")
```

## The aftermath {.smaller}

```{r}
fs::dir_tree("workdir/part2")
```

## Some comments on this

* The `data.csv` file has been copied from the final copy of `incoming` into `analysis`
* The dependency system works interactively too (try it!)
* The logs indicate how dependency resolution occurred
* Metadata about the dependencies is included:

```{r}
orderly_metadata(id)$depends
```

## Using specific versions

```{r}
#| echo: false
#| results: asis
id_old <- orderly_search(name = "incoming")[[2]]
code <- readLines("workdir/part2/src/analysis/analysis.R")
writeLines(sub("latest", id_old, code),
           "workdir/part2/src/analysis/analysis.R")
r_output(readLines("workdir/part2/src/analysis/analysis.R"))
```

## Running this {.smaller}

```{r}
id <- orderly_run("analysis")
```

with metadata

```{r}
orderly_metadata(id)$depends
```

# Part 3: Collaboration {background="#43464B"}

## Working with other people

* Where do you store your code?
* Where do you store your data?
* Where do you store your outputs?
* How will things change over time?
* Is it sensitive?

## The setup

Here we ignore the git side for now and focus on sharing outputs

```{r}
getwd()
orderly_init("workdir/part3")
```

```{r}
#| include: false
Sys.setenv(ORDERLY_ROOT = "workdir/part3")
```

Thom Rawson has kindly set up a bunch of case data for us to use.  He's put it in an orderly root that we can use as **an orderly location**.

```{r}
orderly_location_add_path("thom", "workdir/part3-upstream")
```

## What has Thom been up to?

```{r}
orderly_location_pull_metadata()
orderly_metadata_extract(location = "thom")
```

## Slightly easier to read, but harder to write

```{r}
orderly_metadata_extract(
  location = "thom",
  extract = c(region = "parameters.region is string",
              year = "parameters.year is number"))
```

## Thom has new data for us!

```{r, echo = TRUE}
d <- readRDS("inputs/part3/cases-2021.rds")
write.csv(d$london,
          file.path(path_upstream, "src/cases/cases.csv"),
          row.names = FALSE)
orderly_run("cases", list(region = "london", year = 2021),
            root = "workdir/part3-upstream")
```

# Some thoughts {background="#43464B"}

## Documentation

[The orderly reference](https://mrc-ide.github.io/orderly2/reference/index.html#from-within-a-running-report){preview-link="true"}

# Details for writing reports/tasks

* Shared resources
* Resources
* Loops over dependencies
* Metadata

# What is saved?

* Information about files you consumed, and produced

# Ways of collaborating

# Assorted issues

## Misc

* How to get data into orderly in the first place
  - git versioned files
  - git ignored files
  - files from canonical locations
  - databases
* Coping with failure
* Running knitr/rmarkdown

## The right number of packets

* Similar to "how big is a git repo"
* Some issues:
  * People fragmenting packets to overcome flakey analysis
  * Millions of packets, leading to complex and slow queries
  * Hard to get the right combination of packets

## The right number of parameters

* Too few is too inflexible
* Too many 

## Interaction with git

* Don't save outputs
* Save some inputs?
* Don't save secrets
* Don't save locations
